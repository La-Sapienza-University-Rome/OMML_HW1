{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.255, random_state=1939671)\n",
    "\n",
    "X = np.array(train[['x1', 'x2']])\n",
    "y = np.array(train['y'])\n",
    "\n",
    "X_test = np.array(train[['x1', 'x2']])\n",
    "y_test = np.array(train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def J(f, x, dx=1e-8):\n",
    "    n = x.shape\n",
    "    func = f(x)\n",
    "    jac = np.zeros(n)\n",
    "    x_plus = x.copy()\n",
    "    for i in range(n[0]):\n",
    "        for j in range(n[1]):  # through columns to allow for vector addition\n",
    "            x_plus[i, j] = x[i, j] + dx\n",
    "            jac[i, j] = (f(x_plus) - func)/dx\n",
    "            x_plus = x.copy()\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_(f, x, dx=1e-8):\n",
    "    n = x.shape\n",
    "    func = f(x)\n",
    "    jac = np.zeros(n)\n",
    "    x_plus = x.copy()\n",
    "    for i in range(n[0]):\n",
    "        x_plus[i] = x[i] + dx\n",
    "        jac[i] = (f(x_plus) - func)/dx\n",
    "        x_plus = x.copy()\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "P = len(y)\n",
    "rho = 0\n",
    "sigma = 1\n",
    "\n",
    "W = np.random.randn(X.shape[1], N)\n",
    "b = np.random.randn(N)\n",
    "v = np.random.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(s, sigma):\n",
    "    prod = 2*sigma*s\n",
    "    return (np.exp(prod)-1)/(np.exp(prod)+1)\n",
    "\n",
    "def feedforward(X, W, b, v, sigma):\n",
    "    \n",
    "    linear_layer = (np.dot(X, W) + b)\n",
    "    activation = tanh(linear_layer, sigma)\n",
    "    pred = np.dot(activation, v)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_v(v, X=X, y=y, sigma=sigma, N=N, rho=rho, b=b, W=W):\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((W, v, b), axis=None)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    pred = feedforward(X, W, b, v, sigma)\n",
    "    res = ((np.sum((pred-y)**2))*P**(-1) + rho*norm)*0.5    \n",
    "    \n",
    "    return res\n",
    "\n",
    "def loss_b(b, X=X, y=y, sigma=sigma, N=N, rho=rho, W=W, v=v):\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((W, v, b), axis=None)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    pred = feedforward(X, W, b, v, sigma)\n",
    "    res = ((np.sum((pred-y)**2))*P**(-1) + rho*norm)*0.5    \n",
    "    \n",
    "    return res\n",
    "\n",
    "def loss_W(W, X=X, y=y, sigma=sigma, N=N, rho=rho, b=b, v=v):\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((W, v, b), axis=None)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    pred = feedforward(X, W, b, v, sigma)\n",
    "    res = ((np.sum((pred-y)**2))*P**(-1) + rho*norm)*0.5    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(f, x, dx=1e-8):\n",
    "    n = x.shape\n",
    "    func = f(x)\n",
    "    jac = np.zeros(n)\n",
    "    x_plus = x.copy()\n",
    "    for i in range(n[0]):\n",
    "        for j in range(n[1]):  # through columns to allow for vector addition\n",
    "            x_plus[i, j] = x[i, j] + dx\n",
    "            jac[i, j] = (f(x_plus) - func)/dx\n",
    "            x_plus = x.copy()\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = {}\n",
    "\n",
    "linear_layer = (np.dot(X, W) + b)\n",
    "a_2 = tanh(linear_layer, sigma)\n",
    "dJdf = (1/P)*(np.dot(a_2, v) - y)\n",
    "dtanh = 1 - tanh(linear_layer, sigma)**2\n",
    "\n",
    "dW1_1 = np.tensordot(dJdf, np.transpose(v), axes=0)\n",
    "dW1_2 = dW1_1*dtanh\n",
    "\n",
    "grads['v'] = np.dot(dJdf, a_2) + rho*v\n",
    "grads['b'] = np.sum(dW1_2, axis=0) + rho*b\n",
    "grads['W'] = np.tensordot(np.transpose(X), dW1_2, axes=1) + rho*W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80613596,  0.74883886, -0.86719467, -0.2842885 , -1.51427066,\n",
       "        0.42305066,  0.10000303, -0.72764239,  0.10300871,  0.75171336])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_(loss_b, b).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80613599,  0.74883879, -0.86719474, -0.28428863, -1.51427073,\n",
       "        0.42305048,  0.10000305, -0.72764253,  0.1030087 ,  0.75171325])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['b'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42828932,  0.25427891,  2.04459676,  2.22529222,  1.23179626,\n",
       "       -0.77665261, -1.93779748, -0.35375036,  0.4781664 ,  1.14949685])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_(loss_v, v).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42828943,  0.25427877,  2.04459668,  2.22529217,  1.23179624,\n",
       "       -0.77665272, -1.93779762, -0.35375037,  0.47816636,  1.14949678])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['v'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38439536,  0.68766992],\n",
       "       [-0.06041025, -0.61983849],\n",
       "       [ 0.43542601,  0.09192327],\n",
       "       [-0.01864349, -0.14470665],\n",
       "       [ 0.39348524,  0.30274565],\n",
       "       [-0.01730402, -0.22060931],\n",
       "       [-0.02837943,  0.04287344],\n",
       "       [ 0.01389466,  0.57564229],\n",
       "       [ 0.01219274, -0.12404229],\n",
       "       [-0.29863125, -0.33205154]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(loss_W, W).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38439525,  0.68766982],\n",
       "       [-0.06041032, -0.61983862],\n",
       "       [ 0.43542586,  0.09192315],\n",
       "       [-0.0186436 , -0.14470671],\n",
       "       [ 0.39348512,  0.30274559],\n",
       "       [-0.01730416, -0.2206094 ],\n",
       "       [-0.02837951,  0.04287343],\n",
       "       [ 0.01389457,  0.57564218],\n",
       "       [ 0.01219269, -0.12404235],\n",
       "       [-0.29863126, -0.33205161]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['W'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "c = np.random.randn(X.shape[1], N)\n",
    "v = np.random.randn(N)\n",
    "sigma = 1\n",
    "P = len(y)\n",
    "rho=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(X, c, sigma):\n",
    "    \"\"\"\n",
    "    This function is only applied for a single observation\n",
    "    x belongs to R^2\n",
    "    c belongs to R^{2, 10}\n",
    "    return R^10, 186\n",
    "    \"\"\"\n",
    "    minus_matrix = []\n",
    "    for i in range(len(c.T)):\n",
    "        minus_matrix.append(X - c.T[i])\n",
    "    minus_matrix = np.array(minus_matrix)\n",
    "\n",
    "    return np.exp(-(np.linalg.norm(minus_matrix, axis=2)/sigma)**2)\n",
    "\n",
    "def feedforward(X, c, v, sigma):\n",
    "    \"\"\"\n",
    "    This function is only applied for a single observation\n",
    "    x belongs to R^2\n",
    "    c belongs to R^{2, 10}\n",
    "    v belongs to R^N\n",
    "    return float\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.dot(rbf(X, c, sigma).T, v)\n",
    "    return pred\n",
    "    \n",
    "def loss_v(v, X=X, y=y, sigma=sigma, N=N, rho=rho, c=c):\n",
    "\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((v, c), axis=None)\n",
    "    sum_ = np.sum((feedforward(X, c, v, sigma) - y)**2)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    res = (sum_*P**(-1) + rho*norm)*0.5 \n",
    "    \n",
    "    return res\n",
    "\n",
    "def loss_c(c, X=X, y=y, sigma=sigma, N=N, rho=rho, v=v):\n",
    "    \n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((v, c), axis=None)\n",
    "    sum_ = np.sum((feedforward(X, c, v, sigma) - y)**2)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    res = (sum_*P**(-1) + rho*norm)*0.5 \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = {}\n",
    "\n",
    "z_1 = rbf(X, c, sigma).T\n",
    "dJdf = (1/P)*(np.dot(z_1, v) - y)\n",
    "\n",
    "minus_matrix = []\n",
    "for i in range(len(c.T)):\n",
    "    minus_matrix.append(X - c.T[i])\n",
    "minus_matrix = np.array(minus_matrix)\n",
    "\n",
    "dW1_1 = np.dot(dJdf.reshape((P, 1)), v.reshape((1,N)))\n",
    "dzdc = ((2*z_1)/(sigma**2))*minus_matrix.T\n",
    "\n",
    "grads['v'] = np.dot(dJdf, z_1) + rho*v\n",
    "grads['c'] = np.sum(dzdc*dW1_1, axis=1) + rho*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19615518,  0.10415326, -0.13837911,  0.14623971, -0.05062377,\n",
       "        0.23559342,  0.20378928, -0.16549224,  0.10545867,  0.17595784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['v'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19615516,  0.10415326, -0.13837913,  0.14623971, -0.05062377,\n",
       "        0.23559343,  0.20378927, -0.16549224,  0.10545866,  0.17595785])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_(loss_v, v).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03341052,  0.19978988],\n",
       "       [-0.0038941 , -0.0527783 ],\n",
       "       [ 0.01005668,  0.00831174],\n",
       "       [ 0.06070191, -0.05972991],\n",
       "       [-0.01080392, -0.04613853],\n",
       "       [-0.08542633, -0.01771355],\n",
       "       [-0.05303662,  0.01380043],\n",
       "       [ 0.00360469, -0.04113533],\n",
       "       [ 0.24430081,  0.47257123],\n",
       "       [-0.0947091 ,  0.5037001 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['c'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03341052,  0.19978985],\n",
       "       [-0.00389409, -0.05277829],\n",
       "       [ 0.01005667,  0.00831173],\n",
       "       [ 0.06070191, -0.05972993],\n",
       "       [-0.01080394, -0.04613854],\n",
       "       [-0.08542633, -0.01771354],\n",
       "       [-0.05303664,  0.01380043],\n",
       "       [ 0.00360469, -0.04113534],\n",
       "       [ 0.2443008 ,  0.47257123],\n",
       "       [-0.09470909,  0.5037001 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(loss_c, c).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
