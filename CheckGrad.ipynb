{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.255, random_state=1939671)\n",
    "\n",
    "X = np.array(train[['x1', 'x2']])\n",
    "y = np.array(train['y'])\n",
    "\n",
    "X_test = np.array(train[['x1', 'x2']])\n",
    "y_test = np.array(train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def J(f, x, dx=1e-8):\n",
    "    n = x.shape\n",
    "    func = f(x)\n",
    "    jac = np.zeros(n)\n",
    "    x_plus = x.copy()\n",
    "    for i in range(n[0]):\n",
    "        for j in range(n[1]):  # through columns to allow for vector addition\n",
    "            x_plus[i, j] = x[i, j] + dx\n",
    "            jac[i, j] = (f(x_plus) - func)/dx\n",
    "            x_plus = x.copy()\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_(f, x, dx=1e-8):\n",
    "    n = x.shape\n",
    "    func = f(x)\n",
    "    jac = np.zeros(n)\n",
    "    x_plus = x.copy()\n",
    "    for i in range(n[0]):\n",
    "        x_plus[i] = x[i] + dx\n",
    "        jac[i] = (f(x_plus) - func)/dx\n",
    "        x_plus = x.copy()\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "P = len(y)\n",
    "rho = 1e-3\n",
    "sigma = 1\n",
    "\n",
    "W = np.random.randn(X.shape[1], N)\n",
    "b = np.random.randn(N)\n",
    "v = np.random.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(s, sigma):\n",
    "    prod = 2*sigma*s\n",
    "    return (np.exp(prod)-1)/(np.exp(prod)+1)\n",
    "\n",
    "def feedforward(X, W, b, v, sigma):\n",
    "    \n",
    "    linear_layer = (np.dot(X, W) + b)\n",
    "    activation = tanh(linear_layer, sigma)\n",
    "    pred = np.dot(activation, v)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_v(v, X=X, y=y, sigma=sigma, N=N, rho=rho, b=b, W=W):\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((W, v, b), axis=None)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    pred = feedforward(X, W, b, v, sigma)\n",
    "    res = (0.5*(np.sum((pred-y)**2)))*(P**(-1)) + rho*(norm**2)*0.5\n",
    "    \n",
    "    return res\n",
    "\n",
    "def loss_b(b, X=X, y=y, sigma=sigma, N=N, rho=rho, W=W, v=v):\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((W, v, b), axis=None)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    pred = feedforward(X, W, b, v, sigma)\n",
    "    res = (0.5*(np.sum((pred-y)**2)))*(P**(-1)) + rho*(norm**2)*0.5  \n",
    "    \n",
    "    return res\n",
    "\n",
    "def loss_W(W, X=X, y=y, sigma=sigma, N=N, rho=rho, b=b, v=v):\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((W, v, b), axis=None)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    pred = feedforward(X, W, b, v, sigma)\n",
    "    res = (0.5*(np.sum((pred-y)**2)))*(P**(-1)) + rho*(norm**2)*0.5    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = {}\n",
    "\n",
    "linear_layer = (np.dot(X, W) + b)\n",
    "a_2 = tanh(linear_layer, sigma)\n",
    "dJdf = (1/P)*(np.dot(a_2, v) - y)\n",
    "dtanh = 1 - tanh(linear_layer, sigma)**2\n",
    "\n",
    "dW1_1 = np.tensordot(dJdf, np.transpose(v), axes=0)\n",
    "dW1_2 = dW1_1*dtanh\n",
    "\n",
    "grads['v'] = np.dot(dJdf, a_2) + rho*v\n",
    "grads['b'] = np.sum(dW1_2, axis=0) + rho*b\n",
    "grads['W'] = np.tensordot(np.transpose(X), dW1_2, axes=1) + rho*W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1142932 , -0.00761504, -0.16211172,  0.22838718, -0.09441672,\n",
       "       -0.10602359, -0.07632572,  0.10060168, -0.03769984,  0.03246852])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_(loss_b, b).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11429321, -0.00761507, -0.16211174,  0.22838716, -0.09441673,\n",
       "       -0.10602358, -0.07632572,  0.10060166, -0.03769983,  0.03246849])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['b'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.92755827, -0.94161656,  0.85094176, -1.13314851,  0.35112759,\n",
       "        1.18315597,  0.4519958 ,  1.24802177, -0.73780435,  0.33443686])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_(loss_v, v).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.92755826, -0.94161659,  0.85094177, -1.13314854,  0.35112761,\n",
       "        1.18315596,  0.4519958 ,  1.24802175, -0.73780438,  0.33443688])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['v'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01601785, -0.14466048],\n",
       "       [ 0.1393365 ,  0.16025854],\n",
       "       [-0.01724707, -0.03253324],\n",
       "       [ 0.01876093,  0.9048357 ],\n",
       "       [-0.06420353, -0.36777266],\n",
       "       [ 0.01112568, -0.07694121],\n",
       "       [ 0.12707899,  0.4541246 ],\n",
       "       [ 0.04435017,  0.34369378],\n",
       "       [-0.04812697, -0.14638279],\n",
       "       [-0.00386555, -0.01489571]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(loss_W, W).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01601784, -0.14466048],\n",
       "       [ 0.13933652,  0.16025853],\n",
       "       [-0.01724705, -0.03253325],\n",
       "       [ 0.01876093,  0.9048357 ],\n",
       "       [-0.06420352, -0.36777264],\n",
       "       [ 0.01112571, -0.07694121],\n",
       "       [ 0.12707898,  0.45412464],\n",
       "       [ 0.04435016,  0.34369381],\n",
       "       [-0.04812699, -0.14638277],\n",
       "       [-0.00386555, -0.01489571]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['W'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "c = np.random.randn(X.shape[1], N)\n",
    "v = np.random.randn(N)\n",
    "sigma = 1\n",
    "P = len(y)\n",
    "rho=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(X, c, sigma):\n",
    "    \"\"\"\n",
    "    This function is only applied for a single observation\n",
    "    x belongs to R^2\n",
    "    c belongs to R^{2, 10}\n",
    "    return R^10, 186\n",
    "    \"\"\"\n",
    "    minus_matrix = []\n",
    "    for i in range(len(c.T)):\n",
    "        minus_matrix.append(X - c.T[i])\n",
    "    minus_matrix = np.array(minus_matrix)\n",
    "\n",
    "    return np.exp(-(np.linalg.norm(minus_matrix, axis=2)/sigma)**2)\n",
    "\n",
    "def feedforward(X, c, v, sigma):\n",
    "    \"\"\"\n",
    "    This function is only applied for a single observation\n",
    "    x belongs to R^2\n",
    "    c belongs to R^{2, 10}\n",
    "    v belongs to R^N\n",
    "    return float\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.dot(rbf(X, c, sigma).T, v)\n",
    "    return pred\n",
    "    \n",
    "def loss_v(v, X=X, y=y, sigma=sigma, N=N, rho=rho, c=c):\n",
    "\n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((v, c), axis=None)\n",
    "    sum_ = np.sum((feedforward(X, c, v, sigma) - y)**2)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    res = (sum_*P**(-1) + rho*norm**2)*0.5 \n",
    "    \n",
    "    return res\n",
    "\n",
    "def loss_c(c, X=X, y=y, sigma=sigma, N=N, rho=rho, v=v):\n",
    "    \n",
    "    P = len(y)\n",
    "    x0 = np.concatenate((v, c), axis=None)\n",
    "    sum_ = np.sum((feedforward(X, c, v, sigma) - y)**2)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    res = (sum_*P**(-1) + rho*norm**2)*0.5 \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = {}\n",
    "\n",
    "z_1 = rbf(X, c, sigma).T\n",
    "dJdf = (1/P)*(np.dot(z_1, v) - y)\n",
    "\n",
    "minus_matrix = []\n",
    "for i in range(len(c.T)):\n",
    "    minus_matrix.append(X - c.T[i])\n",
    "minus_matrix = np.array(minus_matrix)\n",
    "\n",
    "dW1_1 = np.dot(dJdf.reshape((P, 1)), v.reshape((1,N)))\n",
    "dzdc = ((2*z_1)/(sigma**2))*minus_matrix.T\n",
    "\n",
    "grads['v'] = np.dot(dJdf, z_1) + rho*v\n",
    "grads['c'] = np.sum(dzdc*dW1_1, axis=1) + rho*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19087348, -0.22647895, -0.15810057, -0.20932393, -0.22179149,\n",
       "       -0.25606286, -0.15235662, -0.19599009, -0.0753367 , -0.16330882])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['v'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19087347, -0.22647897, -0.1581006 , -0.20932394, -0.2217915 ,\n",
       "       -0.25606288, -0.15235664, -0.19599009, -0.07533671, -0.16330883])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_(loss_v, v).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04470326, -0.02547515],\n",
       "       [-0.06439102, -0.09330885],\n",
       "       [-0.06400485, -0.04874972],\n",
       "       [-0.01938205,  0.03204334],\n",
       "       [-0.02653544,  0.05296805],\n",
       "       [-0.00777839,  0.00434297],\n",
       "       [ 0.021409  ,  0.03983179],\n",
       "       [ 0.07787467,  0.05077433],\n",
       "       [-0.0780163 ,  0.01720381],\n",
       "       [ 0.01895447,  0.00404262]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['c'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04470326, -0.02547516],\n",
       "       [-0.06439103, -0.09330885],\n",
       "       [-0.06400485, -0.04874972],\n",
       "       [-0.01938205,  0.03204335],\n",
       "       [-0.02653546,  0.05296805],\n",
       "       [-0.00777838,  0.00434295],\n",
       "       [ 0.02140899,  0.0398318 ],\n",
       "       [ 0.07787466,  0.05077434],\n",
       "       [-0.0780163 ,  0.01720382],\n",
       "       [ 0.01895446,  0.00404263]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(loss_c, c).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An option could be to provide the jacobian directly to the optimizer so that it does the magic while using our jacobian calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x,a):\n",
    "    return (x[0] - 1)**2 + (x[1] - a)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_der(x, a):\n",
    "    dx = 2 * (x[0] - 1)\n",
    "    dy = 2 * (x[1] - a)\n",
    "    return np.array([dx, dy])\n",
    "\n",
    "def fun_hess(x, a):\n",
    "    dx = 2\n",
    "    dy = 2\n",
    "    return np.diag([dx, dy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.0\n",
       "    hess: array([[2, 0],\n",
       "       [0, 2]])\n",
       "     jac: array([0., 0.])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 3\n",
       "    nhev: 2\n",
       "     nit: 2\n",
       "    njev: 3\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1. , 2.5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "x0 = np.array([2, 0])\n",
    "a = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 996 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 1.4396711520283465e-29\n",
       "     jac: array([-2.66453526e-15,  7.10542736e-15])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 3\n",
       "     nit: 1\n",
       "    njev: 3\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1. , 2.5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scipy.optimize.minimize(fun, x0, args=(a,), method='CG', jac=fun_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 4.9251258888196026e-15\n",
       "     jac: array([-3.72266706e-08,  1.45220740e-07])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 9\n",
       "     nit: 1\n",
       "    njev: 3\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([0.99999997, 2.50000007])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scipy.optimize.minimize(fun, x0, args=(a,), method='CG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.255, random_state=1939671)\n",
    "\n",
    "X = np.array(train[['x1', 'x2']])\n",
    "y = np.array(train['y'])\n",
    "\n",
    "X_test = np.array(train[['x1', 'x2']])\n",
    "y_test = np.array(train['y'])\n",
    "\n",
    "def rbf(X, c, sigma):\n",
    "    \"\"\"\n",
    "    This function is only applied for a single observation\n",
    "    x belongs to R^2\n",
    "    c belongs to R^{2, 10}\n",
    "    return R^10, 186\n",
    "    \"\"\"\n",
    "    minus_matrix = []\n",
    "    for i in range(len(c.T)):\n",
    "        minus_matrix.append(X - c.T[i])\n",
    "    minus_matrix = np.array(minus_matrix)\n",
    "\n",
    "    return np.exp(-(np.linalg.norm(minus_matrix, axis=2)/sigma)**2)\n",
    "\n",
    "def feedforward(X, c, v, sigma):\n",
    "    \"\"\"\n",
    "    This function is only applied for a single observation\n",
    "    x belongs to R^2\n",
    "    c belongs to R^{2, 10}\n",
    "    v belongs to R^N\n",
    "    return float\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.dot(rbf(X, c, sigma).T, v)\n",
    "    return pred\n",
    " \n",
    "def backpropagation(x0, funcArgs):\n",
    "\n",
    "    X = funcArgs[0]\n",
    "    y = funcArgs[1]\n",
    "    sigma = funcArgs[2]\n",
    "    N = funcArgs[3]\n",
    "    rho = funcArgs[4]\n",
    "    \n",
    "    c = x0[:int(X.shape[1]*N)].reshape((X.shape[1],N))\n",
    "    v = x0[int(X.shape[1]*N):]\n",
    "    \n",
    "    z_1 = rbf(X, c, sigma).T\n",
    "    dJdf = (1/P)*(np.dot(z_1, v) - y)\n",
    "\n",
    "    minus_matrix = []\n",
    "    for i in range(len(c.T)):\n",
    "        minus_matrix.append(X - c.T[i])\n",
    "    minus_matrix = np.array(minus_matrix)\n",
    "\n",
    "    dW1_1 = np.dot(dJdf.reshape((P, 1)), v.reshape((1,N)))\n",
    "    dzdc = ((2*z_1)/(sigma**2))*minus_matrix.T\n",
    "\n",
    "    dv = np.dot(dJdf, z_1) + rho*v\n",
    "    dc = np.sum(dzdc*dW1_1, axis=1) + rho*c\n",
    "\n",
    "    return np.concatenate((dc, dv), axis=None)\n",
    "    \n",
    "def backpropagation_(X, c, v, sigma, rho):\n",
    "\n",
    "    z_1 = rbf(X, c, sigma).T\n",
    "    dJdf = (1/P)*(np.dot(z_1, v) - y)\n",
    "\n",
    "    minus_matrix = []\n",
    "    for i in range(len(c.T)):\n",
    "        minus_matrix.append(X - c.T[i])\n",
    "    minus_matrix = np.array(minus_matrix)\n",
    "\n",
    "    dW1_1 = np.dot(dJdf.reshape((P, 1)), v.reshape((1,N)))\n",
    "    dzdc = ((2*z_1)/(sigma**2))*minus_matrix.T\n",
    "\n",
    "    dv = np.dot(dJdf, z_1) + rho*v\n",
    "    dc = np.sum(dzdc*dW1_1, axis=1) + rho*c\n",
    "\n",
    "    return np.concatenate((dc, dv), axis=None)\n",
    "    \n",
    "def loss(x0, funcArgs):\n",
    "    \n",
    "    X = funcArgs[0]\n",
    "    y = funcArgs[1]\n",
    "    sigma = funcArgs[2]\n",
    "    N = funcArgs[3]\n",
    "    rho = funcArgs[4]\n",
    "    \n",
    "    c = x0[:int(X.shape[1]*N)].reshape((X.shape[1],N))\n",
    "    v = x0[int(X.shape[1]*N):]\n",
    "\n",
    "    P = len(y)\n",
    "    sum_ = np.sum((feedforward(X, c, v, sigma) - y)**2)\n",
    "    norm = np.linalg.norm(x0)\n",
    "    res = (sum_*P**(-1) + rho*norm**2)*0.5 \n",
    "    \n",
    "    return res\n",
    "    \n",
    "def loss_test(X, y, sigma, N, rho, c, v):\n",
    "\n",
    "    P = len(y)\n",
    "    res = np.sum((feedforward(X, c, v, sigma) - y)**2)*0.5*P**(-1)\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def feedforwardplot(x_i_1, x_i_2, c, v, sigma):\n",
    "    x_i = np.array([x_i_1, x_i_2])\n",
    "    pred = np.dot(np.exp(-(np.linalg.norm((x_i - c.T), axis=1)/sigma)**2), v)\n",
    "    return pred\n",
    "    \n",
    "def train(X, y, sigma, N, rho, c_init, \n",
    "          v_init, max_iter=1000, tol=1e-5, method='CG', func=loss):\n",
    "    \n",
    "    x0 = np.concatenate((c_init, v_init), axis=None)\n",
    "    funcArgs = [X, y, sigma, N, rho]\n",
    "\n",
    "    res = minimize(func,\n",
    "                   x0,\n",
    "                   args=funcArgs, \n",
    "                   method=method, \n",
    "                   tol=tol,\n",
    "                   jac=backpropagation,\n",
    "                   options={'maxiter':max_iter})    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.07847431511569933\n",
       "     jac: array([-4.62310643e-06, -3.00939591e-06, -1.04301414e-06, -9.45444631e-06,\n",
       "       -2.16291659e-08, -2.68615581e-06, -4.70169265e-06,  3.72820209e-07,\n",
       "       -4.53181062e-06, -1.49439709e-06,  2.14375186e-06,  7.97298483e-06,\n",
       "        2.79198181e-06, -1.26696643e-06, -3.63130194e-07, -6.84610568e-06,\n",
       "        1.06034488e-06, -9.51126735e-06,  6.19935585e-07, -5.22809184e-06,\n",
       "        2.71044463e-07,  2.72380215e-06, -4.39337863e-06,  2.30099430e-06,\n",
       "        2.08449442e-06, -1.20964549e-06,  4.36662337e-06,  5.84348808e-06,\n",
       "        5.94325285e-06,  2.28011627e-07])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 327\n",
       "     nit: 152\n",
       "    njev: 327\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 0.89849252, -1.08541308,  0.93694358, -2.31798001,  0.91665066,\n",
       "        0.00856502,  0.89855595, -1.09920623,  0.8985981 , -0.94913158,\n",
       "       -0.29112015, -0.45407855, -2.32734445, -0.39154129,  1.91109257,\n",
       "       -1.37819394, -0.29232558,  0.30958582, -0.29277803, -2.53434306,\n",
       "        0.9899773 ,  2.95379064,  1.33647258, -1.93783349,  0.34202353,\n",
       "       -1.12810126,  0.99448697,  1.95649178,  0.99623521,  1.39430844])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10\n",
    "c = np.random.randn(X.shape[1], N)\n",
    "v = np.random.randn(N)\n",
    "sigma = 1\n",
    "P = len(y)\n",
    "rho=1e-3\n",
    "\n",
    "train(X, y, sigma, N, rho, c, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
